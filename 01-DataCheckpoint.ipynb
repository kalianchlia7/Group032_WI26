{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with your team list and their contributions. Note that this will change over the course of the checkpoints\n",
    "\n",
    "This is a modified [CRediT taxonomy of contributions](https://credit.niso.org). For each group member please list how they contributed to this project using these terms:\n",
    "> Analysis, Background research, Conceptualization, Data curation, Experimental investigation, Methodology, Project administration, Software, Visualization, Writing – original draft, Writing – review & editing\n",
    "\n",
    "Example team list and credits:\n",
    "- Alice Anderson: Conceptualization, Data curation, Methodology, Writing - original draft\n",
    "- Bob Barker:  Analysis, Software, Visualization\n",
    "- Charlie Chang: Project administration, Software, Writing - review & editing\n",
    "- Dani Delgado: Analysis, Background research, Visualization, Writing - original draft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "  - Description of the variables most relevant to this project\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - same as above\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puerto Rico Coral Reef Benthic Cover (CRCP Monitoring Data, 2014–2023)\n",
    "---\n",
    "\n",
    "The Puerto Rico Benthic Cover dataset includes 10,656 reef survey observations collected between 2014 and 2023 as part of NOAA’s Coral Reef Conservation Program. Each row represents one benthic category observed at a specific reef site and date. The dataset contains location information (latitude and longitude in decimal degrees), survey timing (year, month, day), depth measurements in meters, and percent cover values for different benthic groups such as live coral species, macroalgae, cyanobacteria, rubble, and bare substrate.\n",
    "\n",
    "The main variable of interest is percent cover, measured in percentage units (%). Percent cover describes how much of the surveyed reef surface area is occupied by a given category. For example, 30% live coral cover means nearly one-third of the transect area was covered by living coral tissue. In general, coral cover above ~30% is often considered relatively healthy, while values below ~10% may indicate reef degradation. The dataset also includes reef complexity measurements (rugosity), which describe how structurally complex the reef surface is — higher values indicate more three-dimensional structure, which can support greater biodiversity and recovery potential.\n",
    "\n",
    "**Variables We're Focusing On**\n",
    "For this analysis, we’re mainly looking at location and habitat structure variables from the benthic dataset.\n",
    "* Latitude (`degrees_north`) and Longitude (`degrees_east`)\n",
    "These tell us where each survey site is located. We’ll use them to look at spatial patterns and see whether habitat characteristics cluster in certain areas.\n",
    "* Minimum and Maximum Depth\n",
    "These describe how deep the survey area is. DDepth affects light availability, species distribution, and habitat type. We’ll use depth to see whether benthic composition changes across shallow vs. deeper sites.\n",
    "* Substrate Percent Cover (e.g., `hardbottom`, `softbottom`, `rubble`)\n",
    "These variables show what the seafloor is made of at each site. They help us compare habitat composition and determine whether certain substrate types are more common in specific locations or depth ranges.\n",
    "* Mean Rugosity (`MEAN_RUG`)\n",
    "Rugosity measures how complex the seafloor structure is. Since structural complexity often supports greater biodiversity, we’ll use this to assess how habitat complexity varies across sites.\n",
    "\n",
    "By combining location, depth, substrate composition, and rugosity, we can analyze how benthic habitat structure differs across Puerto Rico and identify environmental factors that may explain those differences. These variables together help us understand patterns in habitat composition rather than just describing individual sites.\n",
    "\n",
    "\n",
    "**Concerns and Limitations**\n",
    "\n",
    "There are a few important limitations to keep in mind. Several columns related to zoning and marine protected areas are completely empty, so we can’t use this dataset to analyze management or protection effects in Puerto Rico. Some reef complexity (rugosity) measurements are also missing for many observations, which may reflect changes in survey methods over time rather than random missing data.\n",
    "\n",
    "In addition, several numeric variables (like latitude, depth, and percent cover values) are stored as text and need to be converted before analysis. The first row of the dataset also contains unit labels instead of real data and must be removed during cleaning.\n",
    "\n",
    "Finally, the dataset only covers about 10 years (2014–2023), not the full 20-year period in our research question. While it still captures recent bleaching and stress events, longer-term trends would require additional historical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>REGION</th>\n",
       "      <th>PRIMARY_SAMPLE_UNIT</th>\n",
       "      <th>STATION_NR</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>Date_UTC</th>\n",
       "      <th>...</th>\n",
       "      <th>DEPTH_STRAT</th>\n",
       "      <th>MIN_DEPTH</th>\n",
       "      <th>MAX_DEPTH</th>\n",
       "      <th>METERS_COMPLETED</th>\n",
       "      <th>COVER_CAT_CD</th>\n",
       "      <th>COVER_CAT_NAME</th>\n",
       "      <th>HARDBOTTOM_P</th>\n",
       "      <th>SOFTBOTTOM_P</th>\n",
       "      <th>RUBBLE_P</th>\n",
       "      <th>accession_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UTC</td>\n",
       "      <td>degrees_north</td>\n",
       "      <td>degrees_east</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UTC</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>percent</td>\n",
       "      <td>percent</td>\n",
       "      <td>percent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>18.14334361</td>\n",
       "      <td>-67.30063227</td>\n",
       "      <td>PRICO</td>\n",
       "      <td>6243.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>...</td>\n",
       "      <td>SHLW</td>\n",
       "      <td>8.839199717</td>\n",
       "      <td>9.448799698</td>\n",
       "      <td>15</td>\n",
       "      <td>BAR SUB.</td>\n",
       "      <td>Bare Substrate</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://accession.nodc.noaa.gov/0217139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>18.14334361</td>\n",
       "      <td>-67.30063227</td>\n",
       "      <td>PRICO</td>\n",
       "      <td>6243.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>...</td>\n",
       "      <td>SHLW</td>\n",
       "      <td>8.839199717</td>\n",
       "      <td>9.448799698</td>\n",
       "      <td>15</td>\n",
       "      <td>CYA SPE.</td>\n",
       "      <td>Cyanophyta spp</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://accession.nodc.noaa.gov/0217139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>18.14334361</td>\n",
       "      <td>-67.30063227</td>\n",
       "      <td>PRICO</td>\n",
       "      <td>6243.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>...</td>\n",
       "      <td>SHLW</td>\n",
       "      <td>8.839199717</td>\n",
       "      <td>9.448799698</td>\n",
       "      <td>15</td>\n",
       "      <td>DIC SPE.</td>\n",
       "      <td>Dictyota spp</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://accession.nodc.noaa.gov/0217139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>18.14334361</td>\n",
       "      <td>-67.30063227</td>\n",
       "      <td>PRICO</td>\n",
       "      <td>6243.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>...</td>\n",
       "      <td>SHLW</td>\n",
       "      <td>8.839199717</td>\n",
       "      <td>9.448799698</td>\n",
       "      <td>15</td>\n",
       "      <td>GOR GORG</td>\n",
       "      <td>Gorgonians</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://accession.nodc.noaa.gov/0217139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   time       latitude     longitude REGION  \\\n",
       "0                   UTC  degrees_north  degrees_east    NaN   \n",
       "1  2019-07-18T00:00:00Z    18.14334361  -67.30063227  PRICO   \n",
       "2  2019-07-18T00:00:00Z    18.14334361  -67.30063227  PRICO   \n",
       "3  2019-07-18T00:00:00Z    18.14334361  -67.30063227  PRICO   \n",
       "4  2019-07-18T00:00:00Z    18.14334361  -67.30063227  PRICO   \n",
       "\n",
       "   PRIMARY_SAMPLE_UNIT  STATION_NR    YEAR  MONTH   DAY              Date_UTC  \\\n",
       "0                  NaN         NaN     NaN    NaN   NaN                   UTC   \n",
       "1               6243.0         1.0  2019.0    7.0  18.0  2019-07-18T00:00:00Z   \n",
       "2               6243.0         1.0  2019.0    7.0  18.0  2019-07-18T00:00:00Z   \n",
       "3               6243.0         1.0  2019.0    7.0  18.0  2019-07-18T00:00:00Z   \n",
       "4               6243.0         1.0  2019.0    7.0  18.0  2019-07-18T00:00:00Z   \n",
       "\n",
       "   ... DEPTH_STRAT    MIN_DEPTH    MAX_DEPTH  METERS_COMPLETED COVER_CAT_CD  \\\n",
       "0  ...         NaN            m            m                 m          NaN   \n",
       "1  ...        SHLW  8.839199717  9.448799698                15     BAR SUB.   \n",
       "2  ...        SHLW  8.839199717  9.448799698                15     CYA SPE.   \n",
       "3  ...        SHLW  8.839199717  9.448799698                15     DIC SPE.   \n",
       "4  ...        SHLW  8.839199717  9.448799698                15     GOR GORG   \n",
       "\n",
       "   COVER_CAT_NAME HARDBOTTOM_P  SOFTBOTTOM_P  RUBBLE_P  \\\n",
       "0             NaN      percent       percent   percent   \n",
       "1  Bare Substrate           29             0         0   \n",
       "2  Cyanophyta spp            4             0         0   \n",
       "3    Dictyota spp           18             0         0   \n",
       "4      Gorgonians            1             0         0   \n",
       "\n",
       "                             accession_url  \n",
       "0                                      NaN  \n",
       "1  https://accession.nodc.noaa.gov/0217139  \n",
       "2  https://accession.nodc.noaa.gov/0217139  \n",
       "3  https://accession.nodc.noaa.gov/0217139  \n",
       "4  https://accession.nodc.noaa.gov/0217139  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load Raw Dataset\n",
    "benthic_PR = pd.read_csv(\"data/00-raw/CRCP_Benthic_Cover_Puerto_Rico_07c6_3c17_78b6.csv\")\n",
    "\n",
    "benthic_PR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10656, 34)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benthic_PR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'latitude', 'longitude', 'REGION', 'PRIMARY_SAMPLE_UNIT',\n",
       "       'STATION_NR', 'YEAR', 'MONTH', 'DAY', 'Date_UTC', 'HABITAT_CD', 'STRAT',\n",
       "       'RUGOSITY_CD', 'WTD_RUG', 'MEAN_RUG', 'MAPGRID_NR', 'SUB_REGION_NAME',\n",
       "       'SUB_REGION_NR', 'ZONE_NAME', 'ZONE_NR', 'MPA_NAME', 'MPA_NR', 'ADMIN',\n",
       "       'PROT', 'DEPTH_STRAT', 'MIN_DEPTH', 'MAX_DEPTH', 'METERS_COMPLETED',\n",
       "       'COVER_CAT_CD', 'COVER_CAT_NAME', 'HARDBOTTOM_P', 'SOFTBOTTOM_P',\n",
       "       'RUBBLE_P', 'accession_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benthic_PR.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_SAMPLE_UNIT</th>\n",
       "      <th>STATION_NR</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>RUGOSITY_CD</th>\n",
       "      <th>WTD_RUG</th>\n",
       "      <th>MAPGRID_NR</th>\n",
       "      <th>SUB_REGION_NR</th>\n",
       "      <th>ZONE_NAME</th>\n",
       "      <th>ZONE_NR</th>\n",
       "      <th>MPA_NAME</th>\n",
       "      <th>MPA_NR</th>\n",
       "      <th>PROT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10655.000000</td>\n",
       "      <td>10655.0</td>\n",
       "      <td>10655.000000</td>\n",
       "      <td>10655.000000</td>\n",
       "      <td>10655.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4754.000000</td>\n",
       "      <td>1.062800e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6273.545378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018.363210</td>\n",
       "      <td>8.110371</td>\n",
       "      <td>17.405913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444762</td>\n",
       "      <td>8.270768e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2407.341171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.435621</td>\n",
       "      <td>1.806798</td>\n",
       "      <td>8.820304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.279351</td>\n",
       "      <td>2.906061e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.642914e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6062.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.235417</td>\n",
       "      <td>5.321685e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6321.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>7.981655e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9141.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>1.098570e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9359.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>1.358056e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_SAMPLE_UNIT  STATION_NR          YEAR         MONTH  \\\n",
       "count         10655.000000     10655.0  10655.000000  10655.000000   \n",
       "mean           6273.545378         1.0   2018.363210      8.110371   \n",
       "std            2407.341171         0.0      3.435621      1.806798   \n",
       "min            1000.000000         1.0   2014.000000      4.000000   \n",
       "25%            6062.000000         1.0   2014.000000      7.000000   \n",
       "50%            6321.000000         1.0   2019.000000      8.000000   \n",
       "75%            9141.000000         1.0   2021.000000      9.000000   \n",
       "max            9359.000000         1.0   2023.000000     12.000000   \n",
       "\n",
       "                DAY  RUGOSITY_CD      WTD_RUG    MAPGRID_NR  SUB_REGION_NR  \\\n",
       "count  10655.000000          0.0  4754.000000  1.062800e+04            0.0   \n",
       "mean      17.405913          NaN     0.444762  8.270768e+06            NaN   \n",
       "std        8.820304          NaN     0.279351  2.906061e+06            NaN   \n",
       "min        1.000000          NaN     0.100000  3.642914e+06            NaN   \n",
       "25%       11.000000          NaN     0.235417  5.321685e+06            NaN   \n",
       "50%       18.000000          NaN     0.354167  7.981655e+06            NaN   \n",
       "75%       25.000000          NaN     0.608333  1.098570e+07            NaN   \n",
       "max       31.000000          NaN     1.566667  1.358056e+07            NaN   \n",
       "\n",
       "       ZONE_NAME  ZONE_NR  MPA_NAME  MPA_NR  PROT  \n",
       "count        0.0      0.0       0.0     0.0   0.0  \n",
       "mean         NaN      NaN       NaN     NaN   NaN  \n",
       "std          NaN      NaN       NaN     NaN   NaN  \n",
       "min          NaN      NaN       NaN     NaN   NaN  \n",
       "25%          NaN      NaN       NaN     NaN   NaN  \n",
       "50%          NaN      NaN       NaN     NaN   NaN  \n",
       "75%          NaN      NaN       NaN     NaN   NaN  \n",
       "max          NaN      NaN       NaN     NaN   NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benthic_PR.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Tidy Structure**\n",
    "\n",
    "The dataset is already in long (tidy) format because each row represents one benthic category observation at a specific site and date. Each column represents a single variable (e.g., depth, percent cover, region).\n",
    "**_BUT_**, this does not mean it is *clean*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert Data Types\n",
    "\n",
    "cols_to_numeric = [\n",
    "    \"latitude\", \"longitude\",\n",
    "    \"MIN_DEPTH\", \"MAX_DEPTH\",\n",
    "    \"HARDBOTTOM_P\", \"SOFTBOTTOM_P\", \"RUBBLE_P\",\n",
    "    \"MEAN_RUG\"\n",
    "]\n",
    "\n",
    "for col in cols_to_numeric:\n",
    "    benthic_PR[col] = pd.to_numeric(benthic_PR[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SUB_REGION_NR</th>\n",
       "      <td>10656</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZONE_NR</th>\n",
       "      <td>10656</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPA_NAME</th>\n",
       "      <td>10656</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPA_NR</th>\n",
       "      <td>10656</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RUGOSITY_CD</th>\n",
       "      <td>10656</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROT</th>\n",
       "      <td>10656</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZONE_NAME</th>\n",
       "      <td>10656</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WTD_RUG</th>\n",
       "      <td>5902</td>\n",
       "      <td>55.386637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEAN_RUG</th>\n",
       "      <td>4795</td>\n",
       "      <td>44.998123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPGRID_NR</th>\n",
       "      <td>28</td>\n",
       "      <td>0.262763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAX_DEPTH</th>\n",
       "      <td>24</td>\n",
       "      <td>0.225225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIN_DEPTH</th>\n",
       "      <td>24</td>\n",
       "      <td>0.225225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COVER_CAT_CD</th>\n",
       "      <td>2</td>\n",
       "      <td>0.018769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COVER_CAT_NAME</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADMIN</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HARDBOTTOM_P</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOFTBOTTOM_P</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RUBBLE_P</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEPTH_STRAT</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accession_url</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUB_REGION_NAME</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STRAT</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HABITAT_CD</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAY</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONTH</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATION_NR</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRIMARY_SAMPLE_UNIT</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REGION</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_UTC</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>METERS_COMPLETED</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Missing Count   Missing %\n",
       "SUB_REGION_NR                10656  100.000000\n",
       "ZONE_NR                      10656  100.000000\n",
       "MPA_NAME                     10656  100.000000\n",
       "MPA_NR                       10656  100.000000\n",
       "RUGOSITY_CD                  10656  100.000000\n",
       "PROT                         10656  100.000000\n",
       "ZONE_NAME                    10656  100.000000\n",
       "WTD_RUG                       5902   55.386637\n",
       "MEAN_RUG                      4795   44.998123\n",
       "MAPGRID_NR                      28    0.262763\n",
       "MAX_DEPTH                       24    0.225225\n",
       "MIN_DEPTH                       24    0.225225\n",
       "COVER_CAT_CD                     2    0.018769\n",
       "COVER_CAT_NAME                   1    0.009384\n",
       "ADMIN                            1    0.009384\n",
       "HARDBOTTOM_P                     1    0.009384\n",
       "SOFTBOTTOM_P                     1    0.009384\n",
       "RUBBLE_P                         1    0.009384\n",
       "DEPTH_STRAT                      1    0.009384\n",
       "accession_url                    1    0.009384\n",
       "latitude                         1    0.009384\n",
       "SUB_REGION_NAME                  1    0.009384\n",
       "STRAT                            1    0.009384\n",
       "HABITAT_CD                       1    0.009384\n",
       "DAY                              1    0.009384\n",
       "MONTH                            1    0.009384\n",
       "YEAR                             1    0.009384\n",
       "STATION_NR                       1    0.009384\n",
       "PRIMARY_SAMPLE_UNIT              1    0.009384\n",
       "REGION                           1    0.009384\n",
       "longitude                        1    0.009384\n",
       "Date_UTC                         0    0.000000\n",
       "METERS_COMPLETED                 0    0.000000\n",
       "time                             0    0.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Missing Data Analysis\n",
    "\n",
    "missing_counts = benthic_PR.isna().sum()\n",
    "missing_percent = benthic_PR.isna().mean() * 100\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Missing Count\": missing_counts,\n",
    "    \"Missing %\": missing_percent\n",
    "}).sort_values(\"Missing %\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing info does not seem random; entire columns (e.g., zoning variables) are completely empty, suggesting systematic absence rather than sporadic missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HARDBOTTOM_P</th>\n",
       "      <th>SOFTBOTTOM_P</th>\n",
       "      <th>RUBBLE_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10655.000000</td>\n",
       "      <td>10655.000000</td>\n",
       "      <td>10655.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.681933</td>\n",
       "      <td>1.512529</td>\n",
       "      <td>0.421211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.735646</td>\n",
       "      <td>7.496323</td>\n",
       "      <td>2.470354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HARDBOTTOM_P  SOFTBOTTOM_P      RUBBLE_P\n",
       "count  10655.000000  10655.000000  10655.000000\n",
       "mean       6.681933      1.512529      0.421211\n",
       "std       10.735646      7.496323      2.470354\n",
       "min        0.000000      0.000000      0.000000\n",
       "25%        1.000000      0.000000      0.000000\n",
       "50%        2.000000      0.000000      0.000000\n",
       "75%        7.000000      0.000000      0.000000\n",
       "max       98.000000     98.000000     72.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benthic_PR[[\"HARDBOTTOM_P\", \"SOFTBOTTOM_P\", \"RUBBLE_P\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>REGION</th>\n",
       "      <th>PRIMARY_SAMPLE_UNIT</th>\n",
       "      <th>STATION_NR</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>Date_UTC</th>\n",
       "      <th>...</th>\n",
       "      <th>DEPTH_STRAT</th>\n",
       "      <th>MIN_DEPTH</th>\n",
       "      <th>MAX_DEPTH</th>\n",
       "      <th>METERS_COMPLETED</th>\n",
       "      <th>COVER_CAT_CD</th>\n",
       "      <th>COVER_CAT_NAME</th>\n",
       "      <th>HARDBOTTOM_P</th>\n",
       "      <th>SOFTBOTTOM_P</th>\n",
       "      <th>RUBBLE_P</th>\n",
       "      <th>accession_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [time, latitude, longitude, REGION, PRIMARY_SAMPLE_UNIT, STATION_NR, YEAR, MONTH, DAY, Date_UTC, HABITAT_CD, STRAT, RUGOSITY_CD, WTD_RUG, MEAN_RUG, MAPGRID_NR, SUB_REGION_NAME, SUB_REGION_NR, ZONE_NAME, ZONE_NR, MPA_NAME, MPA_NR, ADMIN, PROT, DEPTH_STRAT, MIN_DEPTH, MAX_DEPTH, METERS_COMPLETED, COVER_CAT_CD, COVER_CAT_NAME, HARDBOTTOM_P, SOFTBOTTOM_P, RUBBLE_P, accession_url]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 34 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benthic_PR[(benthic_PR[\"HARDBOTTOM_P\"] > 100) | (benthic_PR[\"HARDBOTTOM_P\"] < 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MIN_DEPTH</th>\n",
       "      <th>MAX_DEPTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10632.000000</td>\n",
       "      <td>10632.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.819517</td>\n",
       "      <td>13.985222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.597370</td>\n",
       "      <td>6.656109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.304800</td>\n",
       "      <td>0.609600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.924800</td>\n",
       "      <td>9.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.496800</td>\n",
       "      <td>13.716000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.373599</td>\n",
       "      <td>18.592799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29.260799</td>\n",
       "      <td>30.479999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MIN_DEPTH     MAX_DEPTH\n",
       "count  10632.000000  10632.000000\n",
       "mean      12.819517     13.985222\n",
       "std        6.597370      6.656109\n",
       "min        0.304800      0.609600\n",
       "25%        7.924800      9.144000\n",
       "50%       12.496800     13.716000\n",
       "75%       17.373599     18.592799\n",
       "max       29.260799     30.479999"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benthic_PR[[\"MIN_DEPTH\", \"MAX_DEPTH\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No biologically impossible percent values (<0% or >100%) were seen. Depth values fall within reasonable reef ranges (~0–30m), with no extreme outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning Strategy**\n",
    "\n",
    "Columns that are entirely missing (e.g., ZONE_NAME, MPA_NAME, PROT) are going to be dropped because they contain no usable information. Numeric variables stored as text were converted to numeric format. Rows with missing percent cover values were retained only if at least one substrate percent value was present. We avoided aggressive row deletion to preserve ecological observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "benthic_PR = benthic_PR.dropna(axis=1, how='all') # drops fully empty columns\n",
    "\n",
    "benthic_PR = benthic_PR.dropna(subset=[\"YEAR\", \"COVER_CAT_NAME\"]) # drops missing values in essential variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>REGION</th>\n",
       "      <th>PRIMARY_SAMPLE_UNIT</th>\n",
       "      <th>STATION_NR</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>Date_UTC</th>\n",
       "      <th>...</th>\n",
       "      <th>DEPTH_STRAT</th>\n",
       "      <th>MIN_DEPTH</th>\n",
       "      <th>MAX_DEPTH</th>\n",
       "      <th>METERS_COMPLETED</th>\n",
       "      <th>COVER_CAT_CD</th>\n",
       "      <th>COVER_CAT_NAME</th>\n",
       "      <th>HARDBOTTOM_P</th>\n",
       "      <th>SOFTBOTTOM_P</th>\n",
       "      <th>RUBBLE_P</th>\n",
       "      <th>accession_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>18.143344</td>\n",
       "      <td>-67.300632</td>\n",
       "      <td>PRICO</td>\n",
       "      <td>6243.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>...</td>\n",
       "      <td>SHLW</td>\n",
       "      <td>8.8392</td>\n",
       "      <td>9.4488</td>\n",
       "      <td>15</td>\n",
       "      <td>BAR SUB.</td>\n",
       "      <td>Bare Substrate</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://accession.nodc.noaa.gov/0217139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>18.143344</td>\n",
       "      <td>-67.300632</td>\n",
       "      <td>PRICO</td>\n",
       "      <td>6243.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>...</td>\n",
       "      <td>SHLW</td>\n",
       "      <td>8.8392</td>\n",
       "      <td>9.4488</td>\n",
       "      <td>15</td>\n",
       "      <td>CYA SPE.</td>\n",
       "      <td>Cyanophyta spp</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://accession.nodc.noaa.gov/0217139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>18.143344</td>\n",
       "      <td>-67.300632</td>\n",
       "      <td>PRICO</td>\n",
       "      <td>6243.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>...</td>\n",
       "      <td>SHLW</td>\n",
       "      <td>8.8392</td>\n",
       "      <td>9.4488</td>\n",
       "      <td>15</td>\n",
       "      <td>DIC SPE.</td>\n",
       "      <td>Dictyota spp</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://accession.nodc.noaa.gov/0217139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>18.143344</td>\n",
       "      <td>-67.300632</td>\n",
       "      <td>PRICO</td>\n",
       "      <td>6243.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>...</td>\n",
       "      <td>SHLW</td>\n",
       "      <td>8.8392</td>\n",
       "      <td>9.4488</td>\n",
       "      <td>15</td>\n",
       "      <td>GOR GORG</td>\n",
       "      <td>Gorgonians</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://accession.nodc.noaa.gov/0217139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>18.143344</td>\n",
       "      <td>-67.300632</td>\n",
       "      <td>PRICO</td>\n",
       "      <td>6243.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-07-18T00:00:00Z</td>\n",
       "      <td>...</td>\n",
       "      <td>SHLW</td>\n",
       "      <td>8.8392</td>\n",
       "      <td>9.4488</td>\n",
       "      <td>15</td>\n",
       "      <td>HAL SPE.</td>\n",
       "      <td>Halimeda spp</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://accession.nodc.noaa.gov/0217139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   time   latitude  longitude REGION  PRIMARY_SAMPLE_UNIT  \\\n",
       "1  2019-07-18T00:00:00Z  18.143344 -67.300632  PRICO               6243.0   \n",
       "2  2019-07-18T00:00:00Z  18.143344 -67.300632  PRICO               6243.0   \n",
       "3  2019-07-18T00:00:00Z  18.143344 -67.300632  PRICO               6243.0   \n",
       "4  2019-07-18T00:00:00Z  18.143344 -67.300632  PRICO               6243.0   \n",
       "5  2019-07-18T00:00:00Z  18.143344 -67.300632  PRICO               6243.0   \n",
       "\n",
       "   STATION_NR    YEAR  MONTH   DAY              Date_UTC  ... DEPTH_STRAT  \\\n",
       "1         1.0  2019.0    7.0  18.0  2019-07-18T00:00:00Z  ...        SHLW   \n",
       "2         1.0  2019.0    7.0  18.0  2019-07-18T00:00:00Z  ...        SHLW   \n",
       "3         1.0  2019.0    7.0  18.0  2019-07-18T00:00:00Z  ...        SHLW   \n",
       "4         1.0  2019.0    7.0  18.0  2019-07-18T00:00:00Z  ...        SHLW   \n",
       "5         1.0  2019.0    7.0  18.0  2019-07-18T00:00:00Z  ...        SHLW   \n",
       "\n",
       "  MIN_DEPTH  MAX_DEPTH  METERS_COMPLETED  COVER_CAT_CD  COVER_CAT_NAME  \\\n",
       "1    8.8392     9.4488                15      BAR SUB.  Bare Substrate   \n",
       "2    8.8392     9.4488                15      CYA SPE.  Cyanophyta spp   \n",
       "3    8.8392     9.4488                15      DIC SPE.    Dictyota spp   \n",
       "4    8.8392     9.4488                15      GOR GORG      Gorgonians   \n",
       "5    8.8392     9.4488                15      HAL SPE.    Halimeda spp   \n",
       "\n",
       "  HARDBOTTOM_P SOFTBOTTOM_P  RUBBLE_P                            accession_url  \n",
       "1         29.0          0.0       0.0  https://accession.nodc.noaa.gov/0217139  \n",
       "2          4.0          0.0       0.0  https://accession.nodc.noaa.gov/0217139  \n",
       "3         18.0          0.0       0.0  https://accession.nodc.noaa.gov/0217139  \n",
       "4          1.0          0.0       0.0  https://accession.nodc.noaa.gov/0217139  \n",
       "5          8.0          0.0       0.0  https://accession.nodc.noaa.gov/0217139  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benthic_PR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10655, 27)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benthic_PR.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>PRIMARY_SAMPLE_UNIT</th>\n",
       "      <th>STATION_NR</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>WTD_RUG</th>\n",
       "      <th>MEAN_RUG</th>\n",
       "      <th>MAPGRID_NR</th>\n",
       "      <th>MIN_DEPTH</th>\n",
       "      <th>MAX_DEPTH</th>\n",
       "      <th>HARDBOTTOM_P</th>\n",
       "      <th>SOFTBOTTOM_P</th>\n",
       "      <th>RUBBLE_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10655.000000</td>\n",
       "      <td>10655.000000</td>\n",
       "      <td>10655.000000</td>\n",
       "      <td>10655.0</td>\n",
       "      <td>10655.000000</td>\n",
       "      <td>10655.000000</td>\n",
       "      <td>10655.000000</td>\n",
       "      <td>4754.000000</td>\n",
       "      <td>5861.000000</td>\n",
       "      <td>1.062800e+04</td>\n",
       "      <td>10632.000000</td>\n",
       "      <td>10632.000000</td>\n",
       "      <td>10655.000000</td>\n",
       "      <td>10655.000000</td>\n",
       "      <td>10655.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.159688</td>\n",
       "      <td>-66.376224</td>\n",
       "      <td>6273.545378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018.363210</td>\n",
       "      <td>8.110371</td>\n",
       "      <td>17.405913</td>\n",
       "      <td>0.444762</td>\n",
       "      <td>0.354587</td>\n",
       "      <td>8.270768e+06</td>\n",
       "      <td>12.819517</td>\n",
       "      <td>13.985222</td>\n",
       "      <td>6.681933</td>\n",
       "      <td>1.512529</td>\n",
       "      <td>0.421211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.184946</td>\n",
       "      <td>0.885091</td>\n",
       "      <td>2407.341171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.435621</td>\n",
       "      <td>1.806798</td>\n",
       "      <td>8.820304</td>\n",
       "      <td>0.279351</td>\n",
       "      <td>0.218344</td>\n",
       "      <td>2.906061e+06</td>\n",
       "      <td>6.597370</td>\n",
       "      <td>6.656109</td>\n",
       "      <td>10.735646</td>\n",
       "      <td>7.496323</td>\n",
       "      <td>2.470354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.862056</td>\n",
       "      <td>-67.949417</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.642914e+06</td>\n",
       "      <td>0.304800</td>\n",
       "      <td>0.609600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.979148</td>\n",
       "      <td>-67.266039</td>\n",
       "      <td>6062.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.235417</td>\n",
       "      <td>0.196667</td>\n",
       "      <td>5.321685e+06</td>\n",
       "      <td>7.924800</td>\n",
       "      <td>9.144000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.145444</td>\n",
       "      <td>-66.266370</td>\n",
       "      <td>6321.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>7.981655e+06</td>\n",
       "      <td>12.496800</td>\n",
       "      <td>13.716000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.342258</td>\n",
       "      <td>-65.518407</td>\n",
       "      <td>9141.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>1.098570e+07</td>\n",
       "      <td>17.373599</td>\n",
       "      <td>18.592799</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.519091</td>\n",
       "      <td>-65.177250</td>\n",
       "      <td>9359.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>1.243333</td>\n",
       "      <td>1.358056e+07</td>\n",
       "      <td>29.260799</td>\n",
       "      <td>30.479999</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           latitude     longitude  PRIMARY_SAMPLE_UNIT  STATION_NR  \\\n",
       "count  10655.000000  10655.000000         10655.000000     10655.0   \n",
       "mean      18.159688    -66.376224          6273.545378         1.0   \n",
       "std        0.184946      0.885091          2407.341171         0.0   \n",
       "min       17.862056    -67.949417          1000.000000         1.0   \n",
       "25%       17.979148    -67.266039          6062.000000         1.0   \n",
       "50%       18.145444    -66.266370          6321.000000         1.0   \n",
       "75%       18.342258    -65.518407          9141.000000         1.0   \n",
       "max       18.519091    -65.177250          9359.000000         1.0   \n",
       "\n",
       "               YEAR         MONTH           DAY      WTD_RUG     MEAN_RUG  \\\n",
       "count  10655.000000  10655.000000  10655.000000  4754.000000  5861.000000   \n",
       "mean    2018.363210      8.110371     17.405913     0.444762     0.354587   \n",
       "std        3.435621      1.806798      8.820304     0.279351     0.218344   \n",
       "min     2014.000000      4.000000      1.000000     0.100000     0.000000   \n",
       "25%     2014.000000      7.000000     11.000000     0.235417     0.196667   \n",
       "50%     2019.000000      8.000000     18.000000     0.354167     0.316667   \n",
       "75%     2021.000000      9.000000     25.000000     0.608333     0.470000   \n",
       "max     2023.000000     12.000000     31.000000     1.566667     1.243333   \n",
       "\n",
       "         MAPGRID_NR     MIN_DEPTH     MAX_DEPTH  HARDBOTTOM_P  SOFTBOTTOM_P  \\\n",
       "count  1.062800e+04  10632.000000  10632.000000  10655.000000  10655.000000   \n",
       "mean   8.270768e+06     12.819517     13.985222      6.681933      1.512529   \n",
       "std    2.906061e+06      6.597370      6.656109     10.735646      7.496323   \n",
       "min    3.642914e+06      0.304800      0.609600      0.000000      0.000000   \n",
       "25%    5.321685e+06      7.924800      9.144000      1.000000      0.000000   \n",
       "50%    7.981655e+06     12.496800     13.716000      2.000000      0.000000   \n",
       "75%    1.098570e+07     17.373599     18.592799      7.000000      0.000000   \n",
       "max    1.358056e+07     29.260799     30.479999     98.000000     98.000000   \n",
       "\n",
       "           RUBBLE_P  \n",
       "count  10655.000000  \n",
       "mean       0.421211  \n",
       "std        2.470354  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max       72.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benthic_PR.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Processed Dataset\n",
    "\n",
    "benthic_PR.to_csv(\"data/02-processed/benthic_cover_PR_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets*\n",
    "\n",
    "*Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics \n",
    "\n",
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "> This project does not involve human subjects or individual-level data. All datasets used are publicly available environmental monitoring datasets collected by government agencies (e.g., NOAA) using standardized ecological survey methods.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "> Collection bias is relevant because coral reef monitoring sites are not evenly distributed across regions or reef types. Some U.S. reef systems may be monitored more frequently or consistently than others due to accessibility, funding, or conservation priority. This could bias observed recovery pathways toward better-studied regions. We acknowledge this limitation and will avoid overgeneralizing results beyond the monitored sites.\n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "> This project does not collect or use any personally identifiable information. All data are ecological and site-level, such as percent coral cover and thermal stress metrics.\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "> Because this project does not involve human populations or protected groups, downstream bias related to demographic characteristics is not applicable\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    "> The datasets used are publicly available and contain no sensitive information. Data will be stored locally for analysis using standard file protections. While advanced security measures are not required, care will be taken to avoid accidental modification or loss of data.\n",
    "\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "\n",
    "> The project does not use personal or individual-level data. There are no individuals whose data could be removed upon request.\n",
    "\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "> Data will be retained only for the duration of the course project and may be deleted afterward. Since the data are publicly available, long-term storage does not pose ethical concerns.\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "> Our analysis does not include input from reef managers or local communities. Our findings *could* influence policy or funding, e.g., reefs with faster recovery might get more attention, while slower-recovering reefs could be deprioritized. We will clarify that recovery trajectories are descriptive, not value judgments.\n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "> Potential sources of bias include uneven temporal coverage across sites, missing years of data, and unmeasured confounding factors such as storms, pollution, or local management practices. These limitations may affect interpretation of recovery trajectories and will be discussed when presenting results.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "> Visualizations and summary statistics will be designed to accurately reflect the underlying data, including showing uncertainty, missing data, and variability across sites. We will avoid visual choices that exaggerate trends or imply causation.\n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    "> No data with personally identifiable information will be used or displayed, as all data are ecological and environmental in nature.\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "> The data cleaning, merging, and analysis process will be documented using reproducible code and clear descriptions of methods. This allows the analysis to be reviewed or revisited if issues are discovered later.\n",
    "\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    "> This project does not involve predictive models that affect individuals, nor does it include demographic variables.\n",
    "\n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    "\n",
    "> Fairness across human groups is not applicable. However, we recognize that modeling choices may implicitly emphasize certain regions or reef types over others due to data availability.\n",
    "\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    "> Recovery metrics such as changes in percent live coral cover or trajectory slopes were chosen because they are commonly used in reef ecology. We acknowledge that no single metric fully captures reef health and will discuss this limitation.\n",
    "\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    "\n",
    "> The analytical methods used are interpretable and can be explained in clear terms. We will avoid complex models that obscure interpretation.\n",
    "\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "> Limitations such as observational data, lack of causal inference, and incomplete coverage will be clearly communicated in the final report to avoid misinterpretation of results.\n",
    "\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "\n",
    "> This project is exploratory and academic in nature and will not be deployed in a production environment. Ongoing monitoring is therefore not applicable.\n",
    "\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "\n",
    "> Because this analysis does not produce decisions affecting individuals or communities directly, formal redress mechanisms are not required. However, we aim to present findings responsibly to avoid misuse.\n",
    "\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "\n",
    "> There is no deployed system or model to roll back. If errors are discovered, analyses and conclusions can be revised.\n",
    "\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    "> While the project is academic, results could potentially be misused if interpreted as causal or definitive. To mitigate this, we will clearly state the scope, assumptions, and limitations of the analysis.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Replace this with your timeline.  **PLEASE UPDATE your Timeline!** No battle plan survives contact with the enemy, so make sure we understand how your plans have changed.  Also if you have lost points on the previous checkpoint fix them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
