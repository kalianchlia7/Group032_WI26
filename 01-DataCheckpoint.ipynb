{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Paris Aguilar-Ulloa\n",
    "- Kali Anchlia\n",
    "- Julia Berdeski\n",
    "- Ananya Kharya\n",
    "- James Yi\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the past 20 years, what distinct recovery trajectories in percent live coral cover are observed across U.S. coral reef sites following stress events, and how are thermal stress and algal cover associated with these differing pathways?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coral reefs are highly sensitive marine ecosystems that provide important ecological, economic, and coastal protection benefits. In recent years, coral reef health has declined worldwide due to rising sea surface temperatures, more frequent marine heatwaves, and local stressors such as algal overgrowth. Thermal stress, often measured using Degree Heating Weeks (DHW), is strongly linked to coral bleaching events, which can lead to partial or complete loss of live coral cover. <a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) While many studies document coral decline following thermal stress, less is known about how coral reefs recover over time and weather recovery follows consistent patterns across different sites.  <a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2)\n",
    "\n",
    "Being students of University of California, San Diego, part of our academic environment is ingrained with the university’s strengths in marine biology, oceanography, and climate science through programs such as the Scripps Institution of Oceanography. UC San Diego researchers have made major contributions to coral reef monitoring and the study of climate-driven marine stressors, which does add to the motivation for this project. Publicly available datasets from organizations like NOAA and the National Coral Reef Monitoring Program align well with UC San Diego’s emphasis on data-driven marine science and provide a strong foundation for this analysis.\n",
    "\n",
    "Previous research has shown that coral recovery trajectories can vary widely depending on environmental conditions and local ecological dynamics. Studies using NOAA Coral Reef Watch data have found that higher DHW values are associated with more severe bleaching and increased coral mortality, often resulting in slow or incomplete recovery. <a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3) However, more recent monitoring efforts, such as the National Coral Reef Monitoring Program (NCRMP), provide long-term, site-level data on percent live coral and algal cover across U.S. reef systems. <a name=\"cite_ref-4\"></a>[<sup>4</sup>](#cite_note-4)\n",
    "\n",
    "While many studies using these data focus on overall trends in reef health, fewer explicitly examine differences in recovery pathways over time. Our project builds on this prior work by identifying coral recovery trajectories and analyzing how thermal stress and algal cover, both individually and together, are associated with differences in recovery outcomes across U.S. coral reef sites.\n",
    "\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Watch, N. C. R. (n.d.). Coral Reef Watch Home. NOAA Coral Reef Watch Daily 5km Satellite Coral Bleaching Heat Stress Monitoring Products (Version 3.1). https://coralreefwatch.noaa.gov/product/5km/index.php  \n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Hughes et Al. (2017, March 16). Global warming and recurrent mass bleaching of corals. Nature News. https://www.nature.com/articles/nature21707 \n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite-ref-3)Liu, G. et Al. (2014, November 20). Reef-scale thermal stress monitoring of coral ecosystems: New 5-km global products from NOAA Coral Reef Watch. MDPI. https://www.mdpi.com/2072-4292/6/11/11579 \n",
    "4. <a name=\"cite_note-4\"></a> [^](#cite-ref-4)National Coral Reef Monitoring Program: Tracking Environmental Conditions. NCRMP | Environmental. (n.d.). https://coralreef.noaa.gov/topics/national-coral-reef-monitoring-program/environmental \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that coral reef sites exposed to higher cumulative thermal stress will exhibit recovery trajectories characterized by slower increases or sustained declines in percent live coral cover. Higher cumulative thermal stress is strongly associated with coral bleaching, reduced repoduction, and decline in health, which can all prevent reef recovery. We also predict that sites with higher algal cover will show poorer recovery outcomes. Elevated algal cover often follows coral loss and can also prove to be detrimental to coral by competing for space and changing the conditions in the area."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "\n",
    "## Florida NCRMP Benthic Cover Data\n",
    "\n",
    "- Dataset name: NCRMP Benthic Cover – Florida\n",
    "- Link: https://www.coris.noaa.gov/monitoring/monitoring_programs/ncrmp/data/\n",
    "- Number of observations: (fill after loading)\n",
    "- Number of variables: (fill after loading)\n",
    "- Relevant variables: PRIMARY_SAMPLE_UNIT (site ID), LATITUDE, LONGITUDE (for matching thermal data), YEAR (filter to 2016/2018/2020), REGION (FLK/PRICO/STX etc.), COVER_CAT_NAME (coral vs algae category), HARDBOTTOM_P (percent cover value)\n",
    "- Planned use: group by PRIMARY_SAMPLE_UNIT + YEAR, sum HARDBOTTOM_P to compute total coral % and total algae %; use lat/long to match to nearest thermal grid point.\n",
    "- Shortcomings: Some reefs are monitored more often than others, which may bias results. Surveys may not occur every year at every site.\n",
    "\n",
    "We will use this dataset to track coral and algae changes across Florida reefs.\n",
    "\n",
    "This dataset contains benthic cover observations from Florida reef monitoring sites collected under the National Coral Reef Monitoring Program (NCRMP).\n",
    "\n",
    "The dataset includes 13,602 observations and 35 variables. Important variables for our analysis include:\n",
    "\n",
    "- PRIMARY_SAMPLE_UNIT: Unique reef site identifier  \n",
    "- LATITUDE and LONGITUDE: Geographic coordinates used to match sites to thermal grid data  \n",
    "- YEAR: Survey year  \n",
    "- REGION: Geographic region classification  \n",
    "- COVER_CAT_NAME: Organism category (coral vs algae)  \n",
    "- HARDBOTTOM_P: Percent hardbottom cover (used to compute total coral and algae percentages)\n",
    "\n",
    "Percent cover values represent the proportion of reef surface covered by different organism categories.\n",
    "\n",
    "One limitation of this dataset is uneven monitoring across sites and missing values in certain habitat and substrate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "florida = pd.read_csv(\"data/00-raw/CRCP_Benthic_Cover_Florida_7018_0ee5_9488.csv\")\n",
    "\n",
    "print(florida.shape)\n",
    "florida.head()\n",
    "florida.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "florida = pd.read_csv(\"data/00-raw/CRCP_Benthic_Cover_Florida_7018_0ee5_9488.csv\")\n",
    "\n",
    "print(florida.shape)\n",
    "florida.head()\n",
    "florida.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "florida.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_needed = [\n",
    "    \"PRIMARY_SAMPLE_UNIT\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"YEAR\",\n",
    "    \"REGION\",\n",
    "    \"COVER_CAT_NAME\",\n",
    "    \"HARDBOTTOM_P\"\n",
    "]\n",
    "\n",
    "florida_clean = florida[cols_needed]\n",
    "\n",
    "florida_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "florida_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "florida_clean.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puerto Rico Coral Reef Benthic Cover (CRCP Monitoring Data, 2014–2023)\n",
    "---\n",
    "\n",
    "The Puerto Rico Benthic Cover dataset includes 10,656 reef survey observations collected between 2014 and 2023 through NOAA’s Coral Reef Conservation Program. Each row represents one benthic category (like live coral or algae) measured at a specific reef site on a particular survey date. The dataset includes the site ID (`PRIMARY_SAMPLE_UNIT`), latitude and longitude (in decimal degrees), survey year (and month/day when available), region, the organism category (`COVER_CAT_NAME`), and the percent of hardbottom covered (`HARDBOTTOM_P`).\n",
    "\n",
    "The main variable we care about is percent hardbottom cover, which is measured in percent (%). This tells us how much of the reef surface is covered by a certain organism type. For example, 30% live coral cover means that about one-third of the surveyed reef area was covered by living coral. In many reef systems, coral cover above about 30% is considered relatively healthy, while values below 10% often suggest significant degradation or limited recovery after stress events.\n",
    "\n",
    "Since our research question looks at recovery patterns in live coral cover and how those patterns relate to algal cover, we use COVER_CAT_NAME to separate coral from algae and HARDBOTTOM_P to measure how dominant each group is. By combining location (site and region) with time (year), we can track how coral cover changes over time at different sites and see whether some reefs recover differently than others. This helps us explore whether higher algal cover is associated with weaker coral recovery after stress events.\n",
    "\n",
    "**Variables We're Focusing On**\n",
    "\n",
    "For this analysis, we’re mainly looking at location and habitat structure variables from the benthic dataset.\n",
    "* Site ID (`PRIMARY_SAMPLE_UNIT`)\n",
    "This is the unique identifier for each survey site. It allows us to group observations by location and track changes over time at the same site\n",
    "* Latitude (degrees north) and Longitude (degrees east)\n",
    "These tell us where each survey site is located. We’ll use them to look at spatial patterns and see whether habitat characteristics cluster in certain areas.\n",
    "* Date (`YEAR`, `MONTH`, `DAY`)\n",
    "These variables describe when the observation was recorded. YEAR allows us to evaluate long-term trends, while month/day could help identify seasonal patterns.\n",
    "* Region \n",
    "This categorizes sites into broader geographic areas within Puerto Rico. It allows us to compare coral and algae cover across different parts of the island.\n",
    "* `COVER_CAT_NAME`\n",
    "This identifies the organism category being measured (e.g., coral, algae). This is central to our research question because we are specifically comparing coral vs. algae cover.\n",
    "* Percent Cover (`HARDBOTTOM_P`)\n",
    "This is the key outcome variable. It represents the percentage of hardbottom substrate covered by the organism listed in `COVER_CAT_NAME`.\n",
    "It is measured as a percent (%), ranging theoretically from 0 to 100.\n",
    "> * Values near 0% indicate little to no coverage.\n",
    "> * Values near 100% indicate nearly complete coverage of the hardbottom area by that organism type.\n",
    "> * Values outside 0–100% would be biologically impossible and indicate data issues.\n",
    "\n",
    "By combining site location (latitude and longitude), region, time (year, month, day), organism category (coral vs. algae), and percent hardbottom cover, we can analyze how benthic community composition varies across Puerto Rico and over time. These variables allow us to examine both spatial differences between regions and temporal trends within sites. Rather than simply describing individual survey locations, this approach helps us identify broader patterns in coral and algae cover and assess how benthic communities may be shifting across space and time.\n",
    "\n",
    "\n",
    "**Concerns and Limitations**\n",
    "\n",
    "One major concern is sampling bias. Survey sites are not randomly distributed across all reef habitat — they are likely chosen based on accessibility, monitoring priorities, or ecological importance. This means results may not represent all reef areas equally.\n",
    "\n",
    "Another limitation is temporal imbalance. Some sites may have been surveyed more frequently than others, and some years may have more complete coverage than others. This could affect trend analysis.\n",
    "\n",
    "In addition, several numeric variables (like latitude, depth, and percent cover values) are stored as text and need to be converted before analysis. The first row of the dataset also contains unit labels instead of real data and must be removed during cleaning.\n",
    "\n",
    "Finally, the dataset only covers about 10 years (2014–2023), not the full 20-year period in our research question. While it still captures recent bleaching and stress events, longer-term trends would require additional historical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Raw Dataset\n",
    "benthic_PR = pd.read_csv(\"data/00-raw/CRCP_Benthic_Cover_Puerto_Rico_07c6_3c17_78b6.csv\")\n",
    "\n",
    "benthic_PR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benthic_PR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benthic_PR.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\n",
    "    \"PRIMARY_SAMPLE_UNIT\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"YEAR\",\n",
    "    \"MONTH\",\n",
    "    \"DAY\",\n",
    "    \"REGION\",\n",
    "    \"COVER_CAT_NAME\",\n",
    "    \"HARDBOTTOM_P\"\n",
    "]\n",
    "\n",
    "benthic_PR = benthic_PR[[col for col in cols_to_keep if col in benthic_PR.columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benthic_PR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benthic_PR[\"YEAR\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Tidy Structure**\n",
    "\n",
    "The dataset is already in long (tidy) format because each row represents one benthic category observation at a specific site and date. Each column represents a single variable (e.g., depth, percent cover, region).\n",
    "**_BUT_**, this does not mean it is *clean*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benthic_PR.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows:\", benthic_PR.shape[0])\n",
    "print(\"Number of columns:\", benthic_PR.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert Data Types\n",
    "\n",
    "numeric_cols = [\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"YEAR\",\n",
    "    \"MONTH\", \n",
    "    \"DAY\",\n",
    "    \"HARDBOTTOM_P\"\n",
    "]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    benthic_PR[col] = pd.to_numeric(benthic_PR[col], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing Data Analysis\n",
    "\n",
    "missing_counts = benthic_PR.isna().sum()\n",
    "missing_percent = benthic_PR.isna().mean() * 100\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Missing Count\": missing_counts,\n",
    "    \"Missing %\": missing_percent\n",
    "}).sort_values(\"Missing %\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = benthic_PR[\n",
    "    (benthic_PR[\"HARDBOTTOM_P\"] < 0) |\n",
    "    (benthic_PR[\"HARDBOTTOM_P\"] > 100)\n",
    "]\n",
    "\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No biologically impossible percent values (<0% or >100%) were seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benthic_PR[\"HARDBOTTOM_P\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning Strategy**\n",
    "\n",
    "Columns that are entirely missing/ not being used for our research question (e.g., ZONE_NAME, MPA_NAME, PROT) are going to be dropped because they contain no usable information (as done above). Numeric variables stored as text were converted to numeric format. (also done above)\n",
    "\n",
    "Because HARDBOTTOM_P is our primary outcome variable, rows missing this value cannot be used for analysis and will be removed.\n",
    "We also drop rows missing essential identifiers (site, year, region, category).\n",
    "\n",
    "*We keep rows with missing MONTH or DAY if YEAR is present, since yearly trends are sufficient for our main analysis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benthic_clean = benthic_PR.dropna(\n",
    "    subset=[\n",
    "        \"PRIMARY_SAMPLE_UNIT\",\n",
    "        \"YEAR\",\n",
    "        \"REGION\",\n",
    "        \"COVER_CAT_NAME\",\n",
    "        \"HARDBOTTOM_P\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benthic_PR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benthic_PR.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benthic_PR.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Processed Dataset\n",
    "\n",
    "benthic_PR.to_csv(\"data/02-processed/benthic_cover_PR_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### U.S. Virgin Islands Benthic Habitat Percent Cover Dataset\n",
    "\n",
    "This dataset contains benthic habitat percent cover observations from U.S. Virgin Islands reef monitoring sites.\n",
    "\n",
    "Link to dataset: https://github.com/COGS108/Group032_WI26/blob/master/data/00-raw/CRCP_Benthic_Cover_USVI_6400_ac60_8c98.csv\n",
    "\n",
    "The dataset includes 26,325 observations and 7 variables. \n",
    "\n",
    "**Important variables for our analysis include:**\n",
    "* PRIMARY_SAMPLE_UNIT: Unique reef site identifier\n",
    "* LATITUDE and LONGITUDE: Geographic coordinates used to locate sites\n",
    "* YEAR: Survey year\n",
    "* REGION: Island or area classification\n",
    "* COVER_CAT_NAME: Habitat category (e.g., coral, algae)\n",
    "* HARDBOTTOM_P: Percent cover value for hardbottom habitats\n",
    "\n",
    "These measurements matter because they describe relative dominance rather than exact quantities. A percent value does not tell us the total amount of coral or algae in an absolute sense,but it shows how much space each category occupies compared to others at that site and year. Looking at these values across multiple years helps reveal patterns of change over time.\n",
    "\n",
    "**Limitations to consider:** \n",
    "The monitoring sites were not selected randomly; they reflect locations that are accessible to researchers or part of established survey programs. As a result, some regions may be sampled more frequently than others. Because benthic cover is visually estimated by divers, environmental conditions and observer judgment can introduce some variability. The dataset also required minor cleaning before analysis, such as removing non-data rows. Even with these limitations, the dataset provides structured, site-specific information that allows for meaningful comparisons across space and time.,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USVI DATASET CLEANING\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "\n",
    "df = pd.read_csv(\"USVI_data.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "#make the dataset tidy or demonstrate that it was already tidy\n",
    "\n",
    "#in the csv we can see that row 1 is a 'unit' row and can be confused with data\n",
    "if pd.isna(pd.to_numeric(df.loc[0, \"YEAR\"], errors=\"coerce\")):\n",
    "    df = df.drop(index=0).reset_index(drop=True)\n",
    "    #pd.isna(True or False) , if coerced to NaN, returns true, and if statement continues\n",
    "\n",
    "print(\"duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after filtering columns: (26325, 7)\n"
     ]
    }
   ],
   "source": [
    "#demonstrate the size of the dataset\n",
    "#only keep columns needed for analysis\n",
    "\n",
    "columns_to_analyze = [\n",
    "    \"PRIMARY_SAMPLE_UNIT\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"YEAR\",\n",
    "    \"REGION\",\n",
    "    \"COVER_CAT_NAME\",\n",
    "    \"HARDBOTTOM_P\"\n",
    "]\n",
    "\n",
    "df = df[columns_to_analyze]\n",
    "\n",
    "print(\"Dataset shape after filtering columns:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Data Summary:\n",
      "                     Missing_Count  Missing_Percent\n",
      "PRIMARY_SAMPLE_UNIT            0.0              0.0\n",
      "latitude                       0.0              0.0\n",
      "longitude                      0.0              0.0\n",
      "YEAR                           0.0              0.0\n",
      "REGION                         0.0              0.0\n",
      "COVER_CAT_NAME                 0.0              0.0\n",
      "HARDBOTTOM_P                   0.0              0.0\n"
     ]
    }
   ],
   "source": [
    "#find out how much data is missing, \n",
    "#where its missing, \n",
    "#and if its missing at random \n",
    "#or seems to have any systematic relationships in its missingness\n",
    "\n",
    "missing_summary = (\n",
    "    df.isna()\n",
    "      .agg(['sum', 'mean']) \n",
    "    #sum- calculates sum of True NaN #mean- proportion of True NaN\n",
    "      .T\n",
    "    #transposes table for readability\n",
    "      .rename(columns={'sum': 'Missing_Count', 'mean': 'Missing_Percent'})\n",
    ")\n",
    "\n",
    "missing_summary['Missing_Percent'] *= 100\n",
    "#converts proportion to percent\n",
    "missing_summary = missing_summary.sort_values('Missing_Percent', ascending=False)\n",
    "#sorts from most missing to least missing\n",
    "\n",
    "print(\"\\nMissing Data Summary:\")\n",
    "print(missing_summary)\n",
    "\n",
    "#systematic missing?\n",
    "\n",
    "great_missing = missing_summary[missing_summary['Missing_Percent'] > 20].index\n",
    "numeric_df = df.select_dtypes(include='number')\n",
    "\n",
    "for column in great_missing:\n",
    "    print(f\"\\nMissingness correlations for {column}:\")\n",
    "    print(numeric_df.corrwith(df[column].isna().astype(int)).dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIMARY_SAMPLE_UNIT    0\n",
      "YEAR                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#find and flag any outliers or suspicious entries\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "def count_outliers(col):\n",
    "    Q1 = col.quantile(0.25)\n",
    "    Q3 = col.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return ((col < Q1 - 1.5 * IQR) | (col > Q3 + 1.5 * IQR)).sum()\n",
    "\n",
    "outlier_counts = df[numeric_cols].apply(count_outliers)\n",
    "print(outlier_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final cleaned df shape: (26325, 7)\n"
     ]
    }
   ],
   "source": [
    "#clean the data or demonstrate that it was already clean. \n",
    "#You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') \n",
    "#and you should justify your choice in some way\n",
    "\n",
    "# Remove columns that are entirely missing\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Remove rows that are entirely missing\n",
    "df = df.dropna(how='all')\n",
    "\n",
    "#using 'all' because if the row/column has completely missing data, its useless\n",
    "#using 'any' instead risks using some important data bc if even 1 value is missing it would be dropped\n",
    "\n",
    "print(\"\\nFinal cleaned df shape:\", df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics \n",
    "\n",
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "> This project does not involve human subjects or individual-level data. All datasets used are publicly available environmental monitoring datasets collected by government agencies (e.g., NOAA) using standardized ecological survey methods.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "> Collection bias is relevant because coral reef monitoring sites are not evenly distributed across regions or reef types. Some U.S. reef systems may be monitored more frequently or consistently than others due to accessibility, funding, or conservation priority. This could bias observed recovery pathways toward better-studied regions. We acknowledge this limitation and will avoid overgeneralizing results beyond the monitored sites.\n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "> This project does not collect or use any personally identifiable information. All data are ecological and site-level, such as percent coral cover and thermal stress metrics.\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "> Because this project does not involve human populations or protected groups, downstream bias related to demographic characteristics is not applicable\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    "> The datasets used are publicly available and contain no sensitive information. Data will be stored locally for analysis using standard file protections. While advanced security measures are not required, care will be taken to avoid accidental modification or loss of data.\n",
    "\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "\n",
    "> The project does not use personal or individual-level data. There are no individuals whose data could be removed upon request.\n",
    "\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "> Data will be retained only for the duration of the course project and may be deleted afterward. Since the data are publicly available, long-term storage does not pose ethical concerns.\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "> Our analysis does not include input from reef managers or local communities. Our findings *could* influence policy or funding, e.g., reefs with faster recovery might get more attention, while slower-recovering reefs could be deprioritized. We will clarify that recovery trajectories are descriptive, not value judgments.\n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "> Potential sources of bias include uneven temporal coverage across sites, missing years of data, and unmeasured confounding factors such as storms, pollution, or local management practices. These limitations may affect interpretation of recovery trajectories and will be discussed when presenting results.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "> Visualizations and summary statistics will be designed to accurately reflect the underlying data, including showing uncertainty, missing data, and variability across sites. We will avoid visual choices that exaggerate trends or imply causation.\n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    "> No data with personally identifiable information will be used or displayed, as all data are ecological and environmental in nature.\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "> The data cleaning, merging, and analysis process will be documented using reproducible code and clear descriptions of methods. This allows the analysis to be reviewed or revisited if issues are discovered later.\n",
    "\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    "> This project does not involve predictive models that affect individuals, nor does it include demographic variables.\n",
    "\n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    "\n",
    "> Fairness across human groups is not applicable. However, we recognize that modeling choices may implicitly emphasize certain regions or reef types over others due to data availability.\n",
    "\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    "> Recovery metrics such as changes in percent live coral cover or trajectory slopes were chosen because they are commonly used in reef ecology. We acknowledge that no single metric fully captures reef health and will discuss this limitation.\n",
    "\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    "\n",
    "> The analytical methods used are interpretable and can be explained in clear terms. We will avoid complex models that obscure interpretation.\n",
    "\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "> Limitations such as observational data, lack of causal inference, and incomplete coverage will be clearly communicated in the final report to avoid misinterpretation of results.\n",
    "\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "\n",
    "> This project is exploratory and academic in nature and will not be deployed in a production environment. Ongoing monitoring is therefore not applicable.\n",
    "\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "\n",
    "> Because this analysis does not produce decisions affecting individuals or communities directly, formal redress mechanisms are not required. However, we aim to present findings responsibly to avoid misuse.\n",
    "\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "\n",
    "> There is no deployed system or model to roll back. If errors are discovered, analyses and conclusions can be revised.\n",
    "\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    "> While the project is academic, results could potentially be misused if interpreted as causal or definitive. To mitigate this, we will clearly state the scope, assumptions, and limitations of the analysis.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Clear communication** - weekly meeting (Tuesday 5:00-6:00PM)\n",
    "- Assign roles for the week/what we want to accomplish by the next meeting\n",
    "<br>\n",
    "<br>\n",
    "2. **Github**\n",
    "- Don't push without verifying with others\n",
    "<br>\n",
    "<br>\n",
    "3. **Disagreements**\n",
    "- Vote for majority\n",
    "- Flip coin if we can’t come to conclusion\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/3  |  5 PM | Think of some project ideas  | Decide on an idea and start working on the proposal | \n",
    "| 2/5  |  5 PM  |  Complete project proposal | Divvy up work and expectations on gathering info | \n",
    "| 2/15 | 5 PM  | Background research on topic  | Discuss ideal dataset(s) and ethics; draft project proposal + start data checkpoint 1.  Divvy up datasets |\n",
    "| 2/18  | 9 AM  | Work on data checkpoint 1 (general data analysis)| Clean up and finalize checkpoint 1|\n",
    "| 2/24  | 5 PM  | Background info on different ways to analyze the data | Discuss how we want to deeply analyze our data and present it. Divvy up work on EDA |\n",
    "| 3/3  | 5 PM  | Work on EDA| Finishing touches on EDA checkpoint + figure out what needs to be done for final submission |\n",
    "| 3/10  | 5 PM  | Work on cleaning up + finishing up requirements for final submission | Turn in Final Project & Group Project Surveys |\n",
    "| 3/13  | 5 PM  | Work on final submission | Discuss video (script, who says what, etc) |\n",
    "| 3/20  | Before 11:59 PM  | Practice for video, Fine detailing submission | Record video, Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
